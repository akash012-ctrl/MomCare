# MomCare Expo ðŸ‘‹

MomCare addresses the gaps urban Indian mothers face in getting timely, culturally relevant prenatal guidance by combining clinically vetted content, multilingual support, and AI-driven personalization so that busy families receive evidence-based reminders, risk alerts, and wellness tips without relying solely on fragmented online advice.

## Project Progress & Features

- **Phase 1 â€“ MVP (Complete):** Supabase infrastructure, secure authentication, chat and voice assistants, memory/RAG pipeline, dashboard, and five tracking screens (symptoms, kicks, nutrition, goals, alerts).
- **Phase 2 â€“ Advanced Features (Complete):** GPT-4o vision image analysis, background job worker, meal logging, posture assessment, image picker, and history surfacing in profile.
- **Phase 3 â€“ Discovery (Complete):** Explore hub with curated resources, search and filtering, bookmarking, and sharing flows.
- **Phase 4 â€“ Edge Functions Migration (Complete):** Unified `lib/supabase-api.ts`, Supabase Edge Functions (`chat-handler`, `voice-handler`, `data-api`, `file-upload`), and decommissioned legacy AI utilities.
- **Phase 5 â€“ Multilingual Support with Realtime Voice (Complete (partially)):**
  - English and Hindi support in chat (gpt-4o-mini) with multilingual system prompts
  - Realtime voice via WebRTC + OpenAI Realtime API with language-aware transcription (Whisper)
  - Language preference stored per user in `user_profiles` table with auto-retrieval on session restore
  - Language selector UI in profile screen with ðŸ‡¬ðŸ‡§ English / ðŸ‡®ðŸ‡³ à¤¹à¤¿à¤‚à¤¦à¥€ toggle
  - All edge functions updated: `chat-handler` (v6), `realtime-token` (v2) with language parameters
  - Frontend wiring complete: chat and voice screens pass `preferredLanguage` to respective handlers

## Technical Overview

### User Flow Diagram

```mermaid
flowchart TD
    A["App Launch â€” LIVE"] --> B{Authenticated?}
    B -- No --> C["Sign Up / Login â€” LIVE"]
    C --> D["Profile Setup â€” LIVE"]
    B -- Yes --> D
    D --> E["Personalized Dashboard â€” LIVE"]
    E --> F["Tracking Modules â€” LIVE"]
    E --> G["AI Assistant (Text) â€” LIVE"]
    G --> H["chat-handler Edge Function â€” LIVE"]
    H --> I["Contextual Response with Language Support â€” LIVE"]
    E --> V["Realtime Voice Entry (WebRTC) â€” Pending"]
    V --> W["Realtime Token Request â€” LIVE"]
    W --> X["realtime-token Edge Function â€” LIVE"]
    X --> Y["Multilingual Voice Session with Whisper Transcription â€” LIVE"]
    D --> LS["Language Selector (Profile Screen) â€” LIVE"]
    LS --> LP["Set preferred_language in user_profiles â€” LIVE"]
    LP --> RET["Language Retrieved on Session Restore â€” LIVE"]
    E --> J["Image Upload Flow â€” PENDING"]
    J --> K["file-upload Edge Function â€” PENDING"]
    K --> L["Vision Processing Queue â€” PENDING"]
    L --> M["Automated Alerts & Doctor Escalation â€” PENDING"]
```

### System Architecture Diagram

```mermaid
flowchart LR
    Client["Expo App â€” LIVE"] --> Auth["Supabase Auth â€” LIVE"]
    Client --> ChatEF["chat-handler Edge Function â€” LIVE"]
    Client --> VoiceEF["realtime-token Edge Function â€” LIVE"]
    Client --> FileEF["file-upload Edge Function â€” PENDING"]
    Client --> LS["Language Selector Component â€” LIVE"]
    LS --> DB
    DataEF --> DB["Postgres + pgvector + user_profiles.preferred_language â€” LIVE"]
    ChatEF --> DB
    ChatEF --> OpenAI["OpenAI GPT-4o-mini Mini with Language Support (EN/HI) â€” LIVE"]
    VoiceEF --> OpenAI
    VoiceEF --> Realtime_voice_model[" gpt-realtime-mini Language-Aware â€” LIVE"]
    FileEF --> Storage["Supabase Storage â€” PENDING"]
    FileEF --> Jobs["Background Jobs Queue â€” PENDING"]
    Jobs --> Alerts["Realtime Notifications â€” PENDING"]
    DB --> Policies["RLS Policies â€” LIVE"]
```

Legend: LIVE = implemented â€¢ PENDING = in progress

Pending items: Image uploads with embeddings and the background job dispatcher must be completed before automated insights and alerts can go live.

### Upcoming Enhancements

- Secure upload of medical test reports with embeddings for context-aware conversations between the user and AI assistant.
- Extended language support: Auto-detect user language preference from device locale (Phase 6).
- Enhanced voice synthesis: Integrate Hindi TTS (currently using English voice for both languages).
- Expanded Edge Function support for ingesting clinical documents and aligning AI responses with physician-approved guidelines.

## Business Opportunity

MomCare can evolve into a sustainable digital maternal-care platform by layering premium guidance on top of the core companion experience, giving expectant parents confidence and clinicians actionable touchpoints.

- Personalized care plans tuned to specific symptoms, medical history, and wellness goals.
- Location-aware doctor and clinic recommendations with referral or lead fees.
- Optional telemedicine sessions, partner bundles with hospitals, and sponsored wellness programs.
